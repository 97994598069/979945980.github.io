我们都知道，Linux 是一个多任务操作系统，它支持远大于cpu数量的任务同时运行，当然，这些任务实际上并不是真的同时运行，而是因为系统在很短的时间内，将cpu轮流分配给他们，造成多任务同时运行的错觉
而在每个任务运行前，cpu都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要系统事先帮它设置好cpu寄存器和程序计数器
cpu寄存器，是cpu内置的容量小，但速度极快的内存。而程序计数器，则是用来存储cpu正在执行的指令位置、或者即将执行的下一条指令位置。她们都是cpu在运行任何任务前，必须依赖环境，因此也被叫做cpu上下文


cpu上下文切换，就是先把前一个任务的cpu上下文（也就是cpu寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计算器，最后再跳转到程序计数器所指的新位置，运行新任务

而这些保存下来的上下文，会存储再系统内核中，并在任务重新调度执行时再次加载进来，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行




怎么查看系统的上下文切换情况:

[root@_i ~]# vmstat 2 10  
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 8826320 208676 5010108    0    0     0     3    1    0  0  0 100  0  0	
 0  0      0 8826552 208676 5010108    0    0     0    14  371  564  0  0 100  0  0	
 0  0      0 8826304 208676 5010108    0    0     0     0  637  559  0  0 100  0  0	
 0  0      0 8826180 208676 5010112    0    0     0     0  638  574  0  0 100  0  0	
 0  0      0 8825808 208676 5010112    0    0     0    14 3461 1188  0  0 99  0  0	
 0  0      0 8825684 208676 5010112    0    0     0     0 1835 1520  0  0 100  0  0	
 0  0      0 8825932 208676 5010116    0    0     0    50 1211 1517  0  0 100  0  0	
 0  0      0 8825932 208676 5010116    0    0     0    32  805 1503  0  0 100  0  0	
 0  0      0 8825808 208676 5010116    0    0     0     0  823 1514  0  0 100  0  0	
 0  0      0 8825684 208676 5010116    0    0     0     0  781 1485  0  0 100  0  0	

cs (context swich):每秒上下文切换的次数
in （interrupt）则是每秒中断的次数
r (Running or Runnable) 是就绪队列的长度，也就是正在运行和等待cpu的进程数
b (Blocked)则是处于不可中断睡眠状态的进程数


vmstat 只给出了系统总体的上下文切换情况，要想查看每个进程的详细情况，就需要使用pidstat。给它加上-w的选项，就可以查看每个进程上下文的情况了
[root@_i ~]# pidstat -w 5
Linux 2.6.32-696.6.3.el6.x86_64 (_i) 	12/29/2018 	_x86_64_	(4 CPU)

05:00:21 PM       PID   cswch/s nvcswch/s  Command
05:00:26 PM         6      0.20      0.00  watchdog/0
05:00:26 PM        10      0.20      0.00  watchdog/1
05:00:26 PM        14      0.20      0.00  watchdog/2
05:00:26 PM        17      0.20      0.00  ksoftirqd/3
05:00:26 PM        18      0.20      0.00  watchdog/3
05:00:26 PM        19      2.00      0.00  events/0
05:00:26 PM        20      0.80      0.00  events/1
05:00:26 PM        21      1.00      0.00  events/2
05:00:26 PM        22      1.00      0.00  events/3
05:00:26 PM        40      0.20      0.00  sync_supers
05:00:26 PM        46      0.40      0.00  kblockd/0
05:00:26 PM       984      0.20      0.00  flush-252:0
05:00:26 PM      1117      0.20      0.00  irqbalance
05:00:26 PM      2221      3.80      0.00  node
05:00:26 PM      2226      3.40      0.00  node
05:00:26 PM      3015      4.60      0.00  PM2
05:00:26 PM      4639      3.00      0.00  node
05:00:26 PM      4640      3.00      0.00  node
05:00:26 PM      6564     12.20      0.00  nginx
05:00:26 PM     14757      0.40      0.00  nginx
05:00:26 PM     14758      2.20      0.00  nginx
05:00:26 PM     14759      6.40      0.00  nginx
05:00:26 PM     14760      2.00      0.00  nginx
05:00:26 PM     15034      0.20      0.00  sshd
05:00:26 PM     15086      0.20      0.00  pidstat
05:00:26 PM     15931      1.00      0.00  zabbix_agentd
05:00:26 PM     15935      1.00      0.00  zabbix_agentd
05:00:26 PM     30708     10.00      0.00  AliYunDun
需关注:
cswch 表示每秒自愿上下文切换的次数（voluntary context swiches);;;所谓自愿上下文切换是指进程无法获取所需资源，导致的上下文切换，比如说I/O、内存、等系统资源不足时，就会发生资源上下文切换
nvcswch 表示每秒非自愿上下文切换的次数 (non voluntary context swiches);;;所谓非自愿上下文切换则是指进程由于时间片已等原因，被系统强制调度。进而发生的上下文切换。比如说，大量进程都在争抢CPU时，就容易发生非自愿上下文切换


案例：
使用sysbench模拟系统多线程调度切换的情况

sysbench是一个多线程的基准测试工具，一般用来评估不同系统参数下的数据库负载情况。
本次用来模拟上下文切换过多问题：

服务器：2C 8G
yum -y install sysbench sysstat    ##安装  

操作需求：打开三个终端；；root用户测试
测试前查看上下文切换：
# 间隔 1 秒后输出 1 组数据
$ vmstat 1 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 6984064  92668 830896    0    0     2    19   19   35  1  0 99  0  0

 ##可以看到目前上下文切换cs

1)在第一个终端运行sysbench，模拟系统多线程调度的瓶颈
# 以 10 个线程运行 5 分钟的基准测试，模拟多线程切换的问题
$ sysbench --threads=10 --max-time=300 threads run

在第二个终端运行vmstat 观察上下文情况
# 每隔 1 秒输出 1 组数据（需要 Ctrl+C 才结束）
$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 6  0      0 6487428 118240 1292772    0    0     0     0 9019 1398830 16 84  0  0  0
 8  0      0 6487428 118240 1292772    0    0     0     0 10191 1392312 16 84  0  0  0

可以看到cs列的上下文切换已经达到了139万。同时，注意观察其他几个指标：
1)r列：就绪队列的长度已经达到了8，远远超过了系统的cpu的个数2，所以肯定会有大量的cpu竞争

2)ur(user)和sy(system)列：这两列的cpu使用率加起来上升到了100%，其中系统cpu使用率，也就是sy列高达84%，说明cpu主要是被内核占用了

3)in列：中断次数也上升到了1万左右，说明中断处理也是个潜在问题

综合这几个指标，我们可以知道，系统的就绪队列过长，也就是正在运行和等待cpu的进程数过多，导致了大量的上下文切换，而上下文切换又导致了系统cpu的占用率过高


那么到底是什么进程导致了这些问题呢？
在第三个终端使用pidstat查看cpu和进程上下文切换的情况
# 每隔 1 秒输出 1 组数据（需要 Ctrl+C 才结束）
# -w 参数表示输出进程切换指标，而 -u 参数则表示输出 CPU 使用指标
$ pidstat -w -u 1
08:06:33      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
08:06:34        0     10488   30.00  100.00    0.00    0.00  100.00     0  sysbench
08:06:34        0     26326    0.00    1.00    0.00    0.00    1.00     0  kworker/u4:2

08:06:33      UID       PID   cswch/s nvcswch/s  Command
08:06:34        0         8     11.00      0.00  rcu_sched
08:06:34        0        16      1.00      0.00  ksoftirqd/1
08:06:34        0       471      1.00      0.00  hv_balloon
08:06:34        0      1230      1.00      0.00  iscsid
08:06:34        0      4089      1.00      0.00  kworker/1:5
08:06:34        0      4333      1.00      0.00  kworker/0:3
08:06:34        0     10499      1.00    224.00  pidstat
08:06:34        0     26326    236.00      0.00  kworker/u4:2
08:06:34     1000     26784    223.00      0.00  sshd

从pidstat的输出你可以发现，cpu使用率的升高果然是sysbench导致的，它的cpu使用率已经达到了100%，但上下文切换则是来自其他进程，包括非资源上下文切换频率最高的pidstat,以及自愿上下文切换频率最高内核线程kworker和sshd

不过可以看到pidstat输出的上下文切换的次数，远远小于vmstat查看的139万；  为什么呢？
在第三个终端里再次使用pidstat查看不过参数改为-wt
# 每隔 1 秒输出一组数据（需要 Ctrl+C 才结束）
# -wt 参数表示输出线程的上下文切换指标
$ pidstat -wt 1
08:14:05      UID      TGID       TID   cswch/s nvcswch/s  Command
...
08:14:05        0     10551         -      6.00      0.00  sysbench
08:14:05        0         -     10551      6.00      0.00  |__sysbench
08:14:05        0         -     10552  18911.00 103740.00  |__sysbench
08:14:05        0         -     10553  18915.00 100955.00  |__sysbench
08:14:05        0         -     10554  18827.00 103954.00  |__sysbench
...

现在就可以看出，虽然sysbench进程（主进程）的上下文切换次数看起来并不多，但是它的子线程的上下文切换却很多

但是之前vmstat看到的中断次数也上升到了1万，但到底是什么类型的中断上升了呢？
既然是中断，那么就是发生在内核态，而pidstat只是一个进程的性能分析工具，怎么才能知道中断发生的类型呢？

没错，那就是从/proc/interrupts这个只读文件中读取，/proc实际上是Linux的一个虚拟文件系统，用于内核空间与用户空间之间的通信。/proc/interrupts就是这种通信机制的一部分，提供看一个只读的中断使用情况
我们在第三个中断里查看该文件得：
# -d 参数表示高亮显示变化的区域
$ watch -d cat /proc/interrupts
           CPU0       CPU1
...
RES:    2450431    5279697   Rescheduling interrupts
...

观察一段时间，你可以发现，变化速度最快得是重调度中断(RES)，这个中断类型表示，唤醒空闲状态的cpu来调度新的任务运行。这是多核处理器系统（SMP）中，调度器用来分散任务到不同cpu的机制，通常也被称为处理器间中断（Inter-Processor Interrupts,IPI）

所以，这里的中断升高还是因为过多任务的调度问题，跟前面上下文切换次数的分析结果是一致的


但是每秒上下文切换多少次才算正常呢？
这个数值其实取决于系统本身的cpu性能。在我看来，如果系统的上下文切换次数比较稳定，那么从数百到一万以内，都应该算是正常的，但当上下文切换次数超过一万次，或者切换次数出现数量级的增长时，就很可能已经出现了性能问题

这时，你还需要根据上下文切换的类型，再做具体分析。比方说:
1.自愿上下文切换变多了，说明进程都在等待资源，有可能发生了I/O等其他问题
2.非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢cpu，说明cpu的确成了瓶颈
3.中断次数变多了，说明cpu被中断处理程序占用，还需要通过查看/proc/interrupts文件来分析具体的中断类型









