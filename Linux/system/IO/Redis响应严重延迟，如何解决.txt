服务器1：redis
http://192.168.0.10:10000/

服务器2：客户端
curl

$ curl http://192.168.0.10:10000/get_cache
{"count":1677,"data":["d97662fa-06ac-11e9-92c7-0242ac110002",...],"elapsed_seconds":10.545469760894775,"type":"good"}

可以看到这个接口调用居然要花10s,长时间的响应时间，显然不能满足实际的应用需求

为了避免分析过程中客户端的请求结束，所以在进行性能分析前，将curl放到一个循环里来执行
$ while true; do curl http://192.168.0.10:10000/get_cache; done

$ top
top - 12:46:18 up 11 days,  8:49,  1 user,  load average: 1.36, 1.36, 1.04
Tasks: 137 total,   1 running,  79 sleeping,   0 stopped,   0 zombie
%Cpu0  :  6.0 us,  2.7 sy,  0.0 ni,  5.7 id, 84.7 wa,  0.0 hi,  1.0 si,  0.0 st
%Cpu1  :  1.0 us,  3.0 sy,  0.0 ni, 94.7 id,  0.0 wa,  0.0 hi,  1.3 si,  0.0 st
KiB Mem :  8169300 total,  7342244 free,   432912 used,   394144 buff/cache
KiB Swap:        0 total,        0 free,        0 used.  7478748 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 9181 root      20   0  193004  27304   8716 S   8.6  0.3   0:07.15 python
 9085 systemd+  20   0   28352   9760   1860 D   5.0  0.1   0:04.34 redis-server
  368 root      20   0       0      0      0 D   1.0  0.0   0:33.88 jbd2/sda1-8
  149 root       0 -20       0      0      0 I   0.3  0.0   0:10.63 kworker/0:1H
 1549 root      20   0  236716  24576   9864 S   0.3  0.3  91:37.30 python3

观察得cpu的iowait很大，内存正常，进程的cpu的使用率正常，判断很有可能是io造成的

$ iostat -d -x 1
Device            r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
...
sda              0.00  492.00      0.00   2672.00     0.00   176.00   0.00  26.35    0.00    1.76   0.00     0.00     5.43   0.00   0.00
观察输出得，磁盘sda每秒的写数据（wKB/s）为2.5MB，I/O使用率(%util)是0。看来，虽然有些I/O操作，但并没有导致磁盘的I/O瓶颈

尴尬了：
cpu、内存、IO都没有问题，但是性能问题确实是存在的

回想一下，今天的案例问题是从redis缓存中查询数据慢。对查询来说，对应的I/O应该是磁盘的读操作，但刚才我们用iostat看到的缺失写操作。虽说I/O本身并没有性能瓶颈，但这里的磁盘写也是比较奇怪的。为什么会有磁盘写呢？
$ pidstat -d 1
12:49:35      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
12:49:36        0       368      0.00     16.00      0.00      86  jbd2/sda1-8
12:49:36      100      9085      0.00    636.00      0.00       1  redis-server
从输出看，I/O最多的进程是PID为9085的redis-server,并且它也刚好在写磁盘，这说明确实是redis-server在进行磁盘写；；但是光找到写还不够，需要使用strace+lsof组合，看看redis到底在写什么

# -f 表示跟踪子进程和子线程，-T 表示显示系统调用的时长，-tt 表示显示跟踪时间
$ strace -f -T -tt -p 9085
[pid  9085] 14:20:16.826131 epoll_pwait(5, [{EPOLLIN, {u32=8, u64=8}}], 10128, 65, NULL, 8) = 1 <0.000055>
[pid  9085] 14:20:16.826301 read(8, "*2\r\n$3\r\nGET\r\n$41\r\nuuid:5b2e76cc-"..., 16384) = 61 <0.000071>
[pid  9085] 14:20:16.826477 read(3, 0x7fff366a5747, 1) = -1 EAGAIN (Resource temporarily unavailable) <0.000063>
[pid  9085] 14:20:16.826645 write(8, "$3\r\nbad\r\n", 9) = 9 <0.000173>
[pid  9085] 14:20:16.826907 epoll_pwait(5, [{EPOLLIN, {u32=8, u64=8}}], 10128, 65, NULL, 8) = 1 <0.000032>
[pid  9085] 14:20:16.827030 read(8, "*2\r\n$3\r\nGET\r\n$41\r\nuuid:55862ada-"..., 16384) = 61 <0.000044>
[pid  9085] 14:20:16.827149 read(3, 0x7fff366a5747, 1) = -1 EAGAIN (Resource temporarily unavailable) <0.000043>
[pid  9085] 14:20:16.827285 write(8, "$3\r\nbad\r\n", 9) = 9 <0.000141>
[pid  9085] 14:20:16.827514 epoll_pwait(5, [{EPOLLIN, {u32=8, u64=8}}], 10128, 64, NULL, 8) = 1 <0.000049>
[pid  9085] 14:20:16.827641 read(8, "*2\r\n$3\r\nGET\r\n$41\r\nuuid:53522908-"..., 16384) = 61 <0.000043>
[pid  9085] 14:20:16.827784 read(3, 0x7fff366a5747, 1) = -1 EAGAIN (Resource temporarily unavailable) <0.000034>
[pid  9085] 14:20:16.827945 write(8, "$4\r\ngood\r\n", 10) = 10 <0.000288>
[pid  9085] 14:20:16.828339 epoll_pwait(5, [{EPOLLIN, {u32=8, u64=8}}], 10128, 63, NULL, 8) = 1 <0.000057>
[pid  9085] 14:20:16.828486 read(8, "*3\r\n$4\r\nSADD\r\n$4\r\ngood\r\n$36\r\n535"..., 16384) = 67 <0.000040>
[pid  9085] 14:20:16.828623 read(3, 0x7fff366a5747, 1) = -1 EAGAIN (Resource temporarily unavailable) <0.000052>
[pid  9085] 14:20:16.828760 write(7, "*3\r\n$4\r\nSADD\r\n$4\r\ngood\r\n$36\r\n535"..., 67) = 67 <0.000060>
[pid  9085] 14:20:16.828970 fdatasync(7) = 0 <0.005415>
[pid  9085] 14:20:16.834493 write(8, ":1\r\n", 4) = 4 <0.000250>
观察得epoll_pwait、read、write、fdatasync这些系统调用都比较频繁，那么。刚才观察到的写磁盘，应该就是write或者fdatasync导致的

$ lsof -p 9085
redis-ser 9085 systemd-network    3r     FIFO   0,12      0t0 15447970 pipe
redis-ser 9085 systemd-network    4w     FIFO   0,12      0t0 15447970 pipe
redis-ser 9085 systemd-network    5u  a_inode   0,13        0    10179 [eventpoll]
redis-ser 9085 systemd-network    6u     sock    0,9      0t0 15447972 protocol: TCP
redis-ser 9085 systemd-network    7w      REG    8,1  8830146  2838532 /data/appendonly.aof
redis-ser 9085 systemd-network    8u     sock    0,9      0t0 15448709 protocol: TCP
观察发现，描述符编号为3的是一个pipe管道，5号是eventpoll，7号是一个普通文件，而8号是一个TCP socket;结合磁盘写的现象，我们知道，只有7号普通文件才会产生磁盘写，而它操作的文件路径是/data/appendonly.aof,相应的系统调用包括write和fdatasync

如果对redis的持久化配比较熟，看到这个文件路径以及fdatasync的系统调用。应该可以想到。这对应着正是redis持久化配置中的appendonly和appendfsync选项。很可能是因为它们的配置不合理，导致磁盘写比较多
$ docker exec -it redis redis-cli config get 'append*'
1) "appendfsync"
2) "always"
3) "appendonly"
4) "yes"
从结果可以发现appendfsync配置的是always，而appendonly配置的是yes

redis提供了两种数据持久化的方式，分别是快照和追加文件

快照方式：
会按照指定的时间间隔，生成数据的快照，并且保存到磁盘文件中，为了避免阻塞主进程，redis还会fork出一个子进程来负责快照的保存。这种方式的性能好，无论备份还是恢复，都比追加文件好很多
不过它的缺点也很明显，在数据量大时，fork子进程需要用到比较大的内存，保存数据也很耗时。所以，需要设置一个比较长的时间间隔来应对，比如至少5分钟。这样，如果发生故障，你丢失的就是几分钟的数据

追加文件：
是用在文件末尾追加记录的方式，对redis写入的数据，依次进行持久化，所以它的持久化也更安全

此外，它还提供了一个用appendfsync选项设置fsync的策略，确保写入的数据都落到磁盘中，具体选项包括always、everysec、no等
always表示，每个操作都会执行一次fsync，是最为安全的方式
everysec表示，每秒钟调用一次fsync,这样可以保证即使是最坏的情况下。也只丢失1秒的数据
而no表示交给操作系统来处理


而刚刚看到的配置是appendfsync配置的always，意味着每次写入数据时，都会调用一次fsync，从而造成比较大的磁盘I/O压力
$ strace -f -p 9085 -T -tt -e fdatasync
strace: Process 9085 attached with 4 threads
[pid  9085] 14:22:52.013547 fdatasync(7) = 0 <0.007112>
[pid  9085] 14:22:52.022467 fdatasync(7) = 0 <0.008572>
[pid  9085] 14:22:52.032223 fdatasync(7) = 0 <0.006769>
...
[pid  9085] 14:22:52.139629 fdatasync(7) = 0 <0.008183>

从这里可以看到，每隔10ms左右，就会有一次fdatasync调用，并且每次调用本身也要消耗7~8ms
不管哪种方式，都可以验证我们猜想，配置确实不合理，这样就找出了redis正在进行写入的文件，也知道了产生大量I/O的原因

为什么查询会有磁盘写呢？理论上不是只应该只有数据读取吗，再次审查一下strace -f -T -tt -p 9085的结果
read(8, "*2\r\n$3\r\nGET\r\n$41\r\nuuid:53522908-"..., 16384)
write(8, "$4\r\ngood\r\n", 10)
read(8, "*3\r\n$4\r\nSADD\r\n$4\r\ngood\r\n$36\r\n535"..., 16384)
write(7, "*3\r\n$4\r\nSADD\r\n$4\r\ngood\r\n$36\r\n535"..., 67)
write(8, ":1\r\n", 4)

细心的你应该记得，根据lsof的分析，文件描述符编号为7的是一个普通文件/data/appendonly.aof,而编号为8的是TCP socket。而观察上面的内容，8号对应TCP读写，是一个标准的"请求 - 响应"格式，即：
1.从 socket 读取 GET uuid:53522908-...后，响应good
2.再从 socket 读取 SADD good 535… 后，响应1

对redis来说，SADD是一个写操作，所以redis还会把它保存到用于持久化的appendonly.aof文件中

观察更多的strace结果，会发现，每当GET返回good时，随后都会有一个SADD操作，这页就导致了，明明是查询接口，redis却有大量的磁盘写













 
 
 
 

 

 
 
 
 
