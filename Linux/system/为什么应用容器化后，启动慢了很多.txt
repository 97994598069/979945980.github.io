基于docker微服务架构带来的优势:
1.使用docker，把应用程序以及相关依赖打包到镜像中后，部署和升级更快更便捷
2.把传统的单体应用拆分成多个更小的微服务应用后，每个微服务的功能都更简单，并且可以单独管理和维护
3.每个微服务都可以根据需求横向扩展，即使发生故障，也只是局部服务不可用，而不像以前那样，导致整个服务不可用

如何分析应用容器化后的性能问题:
预先安装工具：docker   curl   jq   sysstat
##jq工具专门用来在命令行中处理json。为了更好的展示json数据，我们用来格式化json输出

# -m 表示设置内存为 512MB
$ docker run --name tomcat --cpus 0.1 -m 512M -p 8080:8080 -itd feisky/tomcat:8
Unable to find image 'feisky/tomcat:8' locally
8: Pulling from feisky/tomcat
741437d97401: Pull complete
...
22cd96a25579: Pull complete
Digest: sha256:71871cff17b9043842c2ec99f370cc9f1de7bc121cd2c02d8e2092c6e268f7e2
Status: Downloaded newer image for feisky/tomcat:8
WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
2df259b752db334d96da26f19166d662a82283057411f6332f3cbdbcab452249


第二个终端中:
$ curl localhost:8080
curl: (56) Recv failure: Connection reset by peer

$ docker logs -f tomcat
Using CATALINA_BASE:   /usr/local/tomcat
Using CATALINA_HOME:   /usr/local/tomcat
Using CATALINA_TMPDIR: /usr/local/tomcat/temp
Using JRE_HOME:        /docker-java-home/jre
Using CLASSPATH:       /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar

从这儿可以看到,tomcat容器只打印环境变量，还没有应用程序初始化的日志，也就是说tomcat还在启动中，这时候访问它当然没有响应


终端1中继续查看日志的输出docker logs -f 
在终端2中多次执行curl：
$ for ((i=0;i<30;i++)); do curl localhost:8080; sleep 1; done
curl: (56) Recv failure: Connection reset by peer
curl: (56) Recv failure: Connection reset by peer
# 这儿会阻塞一会
Hello, wolrd!
curl: (52) Empty reply from server
curl: (7) Failed to connect to localhost port 8080: Connection refused
curl: (7) Failed to connect to localhost port 8080: Connection refused
发现，curl给出了我们的结果hello wolrd，但是随后又出现了Empty reply from server以及Connection refused的错误，也就是说tomcat响应一次请求后，就再也不响应了

回到终端1中查看日志得：
18-Feb-2019 12:43:32.719 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/docs]
18-Feb-2019 12:43:33.725 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/docs] has finished in [1,006] ms
18-Feb-2019 12:43:33.726 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/manager]
18-Feb-2019 12:43:34.521 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/manager] has finished in [795] ms
18-Feb-2019 12:43:34.722 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler ["http-nio-8080"]
18-Feb-2019 12:43:35.319 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler ["ajp-nio-8009"]
18-Feb-2019 12:43:35.821 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 24096 ms
root@ubuntu:~#
从输出可以看到，tomcat在启动24s后完成初始化，并且正常启动，从日志上来看没有问题

不过细心得你肯定主义到了最后一行，明显是回到了linux得shell终端中，而没有继续等到docker输出得容器日志


输出重新回到shell终端，通常表示上一个命令已经结束，而我们得上一个命令，是docker logs -f 命令，那么，它的退出就只有两种可能了，1.容器退出了 2.dockerd进程退出了

但是究竟是那种情况呢？
终端1中查看容器状态：
$ docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                            PORTS               NAMES
0f2b3fcdd257        feisky/tomcat:8     "catalina.sh run"   2 minutes ago       Exited (137) About a minute ago                       tomcat

可以看出Exited状态，说明是第一种情况，容器已经退出。不过为什么会这样呢？显然，在前面容器的日志里，我们并没有发现线索，那就只能从docker本身入手了

我们可以调用Docker的API，查询容器的状态、退出码以及错误信息，然后确定容器退出的原因。这些可以通过docker inspect命令来完成，比如可以执行如下命令，通过-f选项设置只输出容器的状态：
# 显示容器状态，jq 用来格式化 json 输出
$ docker inspect tomcat -f '{{json .State}}' | jq
{
  "Status": "exited",
  "Running": false,
  "Paused": false,
  "Restarting": false,
  "OOMKilled": true,
  "Dead": false,
  "Pid": 0,
  "ExitCode": 137,
  "Error": "",
  ...
}
可以看出，容器已经处于exited状态，OOMKilled是true，ExitCode是137.这其中，OOMKilled表示容器被OOM杀死了

我们前面提到过，OOM表示内存不足时，某些应用会被系统杀死，可是为什么内存会不足呢？我们的应用分配了256MB的内存，而容器启动时，明明通过-m选项，设置了512MB内存，按说应该时足够的

到这里，我们可以定位OOM相关的日志：
$ dmesg
[193038.106393] java invoked oom-killer: gfp_mask=0x14000c0(GFP_KERNEL), nodemask=(null), order=0, oom_score_adj=0
[193038.106396] java cpuset=0f2b3fcdd2578165ea77266cdc7b1ad43e75877b0ac1889ecda30a78cb78bd53 mems_allowed=0
[193038.106402] CPU: 0 PID: 27424 Comm: java Tainted: G  OE    4.15.0-1037 #39-Ubuntu
[193038.106404] Hardware name: Microsoft Corporation Virtual Machine/Virtual Machine, BIOS 090007  06/02/2017
[193038.106405] Call Trace:
[193038.106414]  dump_stack+0x63/0x89
[193038.106419]  dump_header+0x71/0x285
[193038.106422]  oom_kill_process+0x220/0x440
[193038.106424]  out_of_memory+0x2d1/0x4f0
[193038.106429]  mem_cgroup_out_of_memory+0x4b/0x80
[193038.106432]  mem_cgroup_oom_synchronize+0x2e8/0x320
[193038.106435]  ? mem_cgroup_css_online+0x40/0x40
[193038.106437]  pagefault_out_of_memory+0x36/0x7b
[193038.106443]  mm_fault_error+0x90/0x180
[193038.106445]  __do_page_fault+0x4a5/0x4d0
[193038.106448]  do_page_fault+0x2e/0xe0
[193038.106454]  ? page_fault+0x2f/0x50
[193038.106456]  page_fault+0x45/0x50
[193038.106459] RIP: 0033:0x7fa053e5a20d
[193038.106460] RSP: 002b:00007fa0060159e8 EFLAGS: 00010206
[193038.106462] RAX: 0000000000000000 RBX: 00007fa04c4b3000 RCX: 0000000009187440
[193038.106463] RDX: 00000000943aa440 RSI: 0000000000000000 RDI: 000000009b223000
[193038.106464] RBP: 00007fa006015a60 R08: 0000000002000002 R09: 00007fa053d0a8a1
[193038.106465] R10: 00007fa04c018b80 R11: 0000000000000206 R12: 0000000100000768
[193038.106466] R13: 00007fa04c4b3000 R14: 0000000100000768 R15: 0000000010000000
[193038.106468] Task in /docker/0f2b3fcdd2578165ea77266cdc7b1ad43e75877b0ac1889ecda30a78cb78bd53 killed as a result of limit of /docker/0f2b3fcdd2578165ea77266cdc7b1ad43e75877b0ac1889ecda30a78cb78bd53
[193038.106478] memory: usage 524288kB, limit 524288kB, failcnt 77
[193038.106480] memory+swap: usage 0kB, limit 9007199254740988kB, failcnt 0
[193038.106481] kmem: usage 3708kB, limit 9007199254740988kB, failcnt 0
[193038.106481] Memory cgroup stats for /docker/0f2b3fcdd2578165ea77266cdc7b1ad43e75877b0ac1889ecda30a78cb78bd53: cache:0KB rss:520580KB rss_huge:450560KB shmem:0KB mapped_file:0KB dirty:0KB writeback:0KB inactive_anon:0KB active_anon:520580KB inactive_file:0KB active_file:0KB unevictable:0KB
[193038.106494] [ pid ]   uid  tgid total_vm      rss pgtables_bytes swapents oom_score_adj name
[193038.106571] [27281]     0 27281  1153302   134371  1466368        0             0 java
[193038.106574] Memory cgroup out of memory: Kill process 27281 (java) score 1027 or sacrifice child
[193038.148334] Killed process 27281 (java) total-vm:4613208kB, anon-rss:517316kB, file-rss:20168kB, shmem-rss:0kB
[193039.607503] oom_reaper: reaped process 27281 (java), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB
输出记录了OOM的几个关键点：
1.被杀死的时一个java进程，从内核调用栈上的mem_cgroup_out_of_memory可以看出，它是因为超过cgroup的内存限制，而被OOM杀死的。
2.java进程是在容器内运行的，而容器内存的使用量和限制都是512M(524288KB)。目前使用量已经达到了限制，所以会导致OOM
3.被杀死的进程pid为27281，虚拟内存为4.3G(total-vm:4613208KB),匿名内存为505M(anon-rss:517316KB)，页内存为19M(20168KB)。换句话说，匿名内存是主要的内存占用，而且匿名内存加上页内存，总共是524M，已经超过512M的限制

综合这几点，可以看出，tomcat容器的内存主要用在了匿名内存中，而匿名内存，其实就是主动申请分配的堆内存
不过为什么tomcat会申请这么多的堆内存呢？要知道，tomcat是基于java开发的，所以不难想到，这很可能是JVM堆内存配置的问题

我们知道，JVM根据系统的内存总量，来自动管理内存，不明确配置的话，堆内存的默认限制是物理内存的四分之一，不过我们限制了容器内存为512M，java的堆内存到底是多少呢？


终端1中重启tomcat容器，并用java命令来查看堆内存大小:
# 重新启动容器
$ docker rm -f tomcat
$ docker run --name tomcat --cpus 0.1 -m 512M -p 8080:8080 -itd feisky/tomcat:8

# 查看堆内存，注意单位是字节
$ docker exec tomcat java -XX:+PrintFlagsFinal -version | grep HeapSize
    uintx ErgoHeapSizeLimit                         = 0                                   {product}
    uintx HeapSizePerGCThread                       = 87241520                            {product}
    uintx InitialHeapSize                          := 132120576                           {product}
    uintx LargePageHeapSizeThreshold                = 134217728                           {product}
    uintx MaxHeapSize                              := 2092957696                          {product}

从这里可以看到，初始堆内存的大小（InitialHeapSize）是126MB，而最大堆内存则是1.95GB,这可比容器限制512MB大多了

之所以会这么大，其实是因为，容器内部看不到Docker为它设置的内存限制，虽然在启动容器时，我们通过-m 512M选项，给容器设置512M的内存限制，但是实际上，从容器内部看到的限制却不是512M
$ docker exec tomcat free -m
              total        used        free      shared  buff/cache   available
Mem:           7977         521        1941           0        5514        7148
Swap:             0           0           0

果然，容器内部看到的内存，仍是主机内存
知道了问题的根源，解决方法就很简单了，给JVM正确配置内存限制为512M就可以了
# 删除问题容器
$ docker rm -f tomcat
# 运行新的容器
$ docker run --name tomcat --cpus 0.1 -m 512M -e JAVA_OPTS='-Xmx512m -Xms512m' -p 8080:8080 -itd feisky/tomcat:8


$ top
top - 12:57:18 up 2 days,  5:50,  2 users,  load average: 0.00, 0.02, 0.00
Tasks: 131 total,   1 running,  74 sleeping,   0 stopped,   0 zombie
%Cpu0  :  3.0 us,  0.3 sy,  0.0 ni, 96.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu1  :  5.7 us,  0.3 sy,  0.0 ni, 94.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem :  8169304 total,  2465984 free,   500812 used,  5202508 buff/cache
KiB Swap:        0 total,        0 free,        0 used.  7353652 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
29457 root      20   0 2791736  73704  19164 S  10.0  0.9   0:01.61 java                         27349 root      20   0 1121372  96760  39340 S   0.3  1.2   4:20.82 dockerd
27376 root      20   0 1031760  43768  21680 S   0.3  0.5   2:44.47 docker-containe              29430 root      20   0    7376   3604   3128 S   0.3  0.0   0:00.01 docker-containe
    1 root      20   0   78132   9332   6744 S   0.0  0.1   0:16.12 systemd

	
从top的输出，可以看出：
1.从系统整体来看，两个CPU的使用率分别是3%和5.7%，都不算高，大部分还是空闲的；可用内存还有7GB（7353652 avail mem）,也非常充足

2.具体的进程上，java进程CPU使用率为10%，内存使用0.9%，其他进程就都很低了

这些指标都不算高，看起来没啥问题，不过究竟如何呢？由于java进程的CPU使用率最高，所以要把它当成重点，
# -t 表示显示线程，-p 指定进程号
$ pidstat -t -p 29457 1
12:59:59      UID      TGID       TID    %usr %system  %guest   %wait    %CPU   CPU  Command
13:00:00        0     29457         -    0.00    0.00    0.00    0.00    0.00     0  java
13:00:00        0         -     29457    0.00    0.00    0.00    0.00    0.00     0  |__java
13:00:00        0         -     29458    0.00    0.00    0.00    0.00    0.00     1  |__java
...
13:00:00        0         -     29491    0.00    0.00    0.00    0.00    0.00     0  |__java

结果中，各种CPU使用率全是0.看起来不对，不过tomcat启动已经结束了，在没有客户端请求的情况下，tomcat本身啥也不用做，cpu使用率当然是0


再次重启tomcat并仔细观察得：
# 删除旧容器
$ docker rm -f tomcat
# 运行新容器
$ docker run --name tomcat --cpus 0.1 -m 512M -e JAVA_OPTS='-Xmx512m -Xms512m' -p 8080:8080 -itd feisky/tomcat:8
# 查询新容器中进程的 Pid
$ PID=$(docker inspect tomcat -f '{{.State.Pid}}')
# 执行 pidstat
$ pidstat -t -p $PID 1
12:59:28      UID      TGID       TID    %usr %system  %guest   %wait    %CPU   CPU  Command
12:59:29        0     29850         -   10.00    0.00    0.00    0.00   10.00     0  java
12:59:29        0         -     29850    0.00    0.00    0.00    0.00    0.00     0  |__java
12:59:29        0         -     29897    5.00    1.00    0.00   86.00    6.00     1  |__java
...
12:59:29        0         -     29905    3.00    0.00    0.00   97.00    3.00     0  |__java
12:59:29        0         -     29906    2.00    0.00    0.00   49.00    2.00     1  |__java
12:59:29        0         -     29908    0.00    0.00    0.00   45.00    0.00     0  |__java


仔细观察这次得输出，会发现，虽然CPU使用率（%CPU）很低，但等待运行的使用率(%wait)却非常高，最高甚至已经达到了97%，这说明，这些线程大部分时间都在等待调度，而不是在真正的运行；；这是因为Docker为容器做了限制
$ docker run --name tomcat --cpus 0.1 -m 512M -e JAVA_OPTS='-Xmx512m -Xms512m' -p 8080:8080 -itd feisky/tomcat:8

我们启动的时候限制了cpu为0.1，为容器设置了0.1个CPU的限制，也就是10%的CPU，这里也就可以解释，为什么java进程只有10%的CPU使用率，也会在大部分时间都在等待了


处理：
重启tomcat容器，将cpu限制增大即可：
# 删除旧容器
$ docker rm -f tomcat
# 运行新容器
$ docker run --name tomcat --cpus 1 -m 512M -e JAVA_OPTS='-Xmx512m -Xms512m' -p 8080:8080 -itd feisky/tomcat:8
# 查看容器日志
$ docker logs -f tomcat
...
18-Feb-2019 12:54:02.139 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 2001 ms





	
	











