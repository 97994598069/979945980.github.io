service的访问信息在k8s集群之外，其实是无效的，这其实也容易理解：所谓service的访问入口，其实就是每台宿主机上由kube-proxy生成的iptables规则，以及kube-dns生成的DNS记录，而一旦离开了这个集群，这些信息对用户来说，也就自然没有作用了

所以，在使用k8s的service时，一个必须要面对和解决的问题就是：如何从外部访问到k8s里创建的service
NodePort示例:
apiVersion: v1
kind: Service
metadata:
  name: my-nginx
  labels:
    run: my-nginx
spec:
  type: NodePort
  ports:
  - nodePort: 8080
    targetPort: 80
    protocol: TCP
    name: http
  - nodePort: 443
    protocol: TCP
    name: https
  selector:
    run: my-nginx

在这个Service的定义里，我们声明它的类型是，type=NodePort。然后，我在ports字段里声明了service的8080端口代理pod的80端口，service的443端口代理pod的443端口

当然，如果你不显示地声明nodeport字段，k8s就会为你分配随机的可用端口来设置代理，这个端口的范围默认的是30000-32767，通过kube-apiserver的-service-node-port-range参数来修改它

那么这时候，要访问这个service，你只要访问：任意一台宿主机的ip地址:8080端口，就可以访问到某一个被代理的pod的80端口了

而在理解了，前面提到的servie的工作原理之后，NodePort模式也就非常容易理解了，显然，kube-proxy要做的就是在每台宿主机上生成这样一条iptables规则：
-A KUBE-NODEPORTS -p tcp -m comment --comment "default/my-nginx: nodePort" -m tcp --dport 8080 -j KUBE-SVC-67RL4FN6JRUPOJYM

前面提到过KUBE-SVC-67RL4FN6JRUPOJYM其实就是一组随机模式的iptables规则，所以接下来的流程，就是ClusterIP模式完全不一样了

需要注意的是，在NodePort方式下，k8s会在IP包离开宿主机发往目的pod时，对这个ip包做一个SNAT操作：
-A KUBE-POSTROUTING -m comment --comment "kubernetes service traffic requiring SNAT" -m mark --mark 0x4000/0x4000 -j MASQUERADE

可以看到，这条规则设置POSTROUTING检查点，也就是它给即将离开这台主机的IP包进行了一次SNAT操作，将这个IP包的源地址替换成了这台宿主机的CNI网桥地址，或者宿主机本身的IP地址（如果CNI网桥不存在的话）


当然，这个SNAT操作只需要对service转发出来的IP包进行（否则普通的IP包被影响了）。而iptables做这个判断的依据，就是查看该IP包是否有一个“0x4000”的“标志”。这个标志正是在IP包被执行DNAT操作之前被打上去的


可是为什么一定要对流出的包做SNAT操作呢？
这原理其实很简单:
           client
             \ ^
              \ \
               v \
   node 1 <--- node 2
    | ^   SNAT
    | |   --->
    v |
 endpoint

当一个外部的client通过node2的地址访问一个service的时候，node2上的负载均衡规则，就可能把这个IP包转发给一个node1上的pod

而当node1上的这个pod处理完请求之后，它就会按照这个IP包的源地址发出回复

可是，如果没有做SNAT操作的话，这时候被转发来的IP包的源地址就是client的IP地址。所以此时，Pod就会直接将回复发给client，对于client来说，它的请求明明发给了node2，收到的回复却来自node1，这个client很可能会报错

所以上图中，当IP包离开node2之后，它的源IP地址就会被SNAT改成node2的CNI网桥地址或者node2自己的地址。这样，pod在处理完成之后就会先回复到node2（而不是client）,然后再由node2发送给client

当然，这也意味着这个pod只知道IP包来自于node2,而不是外部的client。对于pod需要明确知道所有请求来源的场景来说，这时不可以的


所以这时候，你可以将service的spec.externalTrafficPolicy字段设置为local，这就保证了所有pod通过service收到请求之后，一定可以看到真正的、外部client的源地址

而这个机制的实现原理也非常简单：这时候，一台宿主机上的iptables规则，会设置为只将IP包转发给运行再这台宿主机上的Pod。这时候，pod就可以直接使用源地址将回复包发出，不需要事先进行SNAT了。这个流程如下:
       client
       ^ /   \
      / /     \
     / v       X
   node 1     node 2
    ^ |
    | |
    | v
 endpoint

当然，这也就意味着如果一台宿主机上，没有任何一个被代理的pod存在，比如上图中的node2，那么你使用node2的IP地址访问这个service，就是无效的，此时你的请求就会直接被DROP掉




从外部访问service的第二种方式，适用于公有云上的k8s服务，这时候，你可以指定一个LoadBalancer类型的service如下:
---
kind: Service
apiVersion: v1
metadata:
  name: example-service
spec:
  ports:
  - port: 8765
    targetPort: 9376
  selector:
    app: example
  type: LoadBalancer

在公有云提供的k8s服务里，都使用了一个叫做cloudProvider的转发层，来跟公有云本身的API进行对接。所以，在上述LoadBalancer类型的Service被提交后，k8s就会调用cloudProvider在公有云上为你创建一个负载均衡服务，并且把被代理的Pod的IP地址配置给负载均衡服务做后端





第三种，就是k8s1.7之后支持的一个新特性，叫做Externalname。
示例；
kind: Service
apiVersion: v1
metadata:
  name: my-service
spec:
  type: ExternalName
  externalName: my.database.example.com

在上述service的YAML文件里，我指定了一个externalName=my.database.example.com的字段，而且你应该会注意到这个YAML文件里不需要指定selector

这时候，当你通过service的DNS名字访问它的时候，比如访问：my-service.default.svc.cluster.local。那么k8s为你返回的就是my.database.example.com。所以说，ExternalName类型的Service，其实是在kube-dns里添加了一条CNAME记录。这时，访问my-service.default.svc.cluster.local就和访问my.database.example.com这个域名是一个效果了

此外，k8s的service还允许你为service分配公有IP地址，如下:
kind: Service
apiVersion: v1
metadata:
  name: my-service
spec:
  selector:
    app: MyApp
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 9376
  externalIPs:
  - 80.11.12.10

在上述service种，我为它指定的externalIPs=80.11.12.10，那么此时，你就可以通过访问80.11.12.10:80访问到被代理的Pod了。不过在这里k8s要求externalIPs必须是至少能够路由到一个k8s的节点;
实际上，在理解了k8s service机制的工作原理之后，很多与service相关的问题，其实都可以通过分析Service在宿主机上对应的iptables规则（或者IPVS配置）得到解决。

比如，当你的service没办法通过DNS访问到的时候，你就需要区分到底service本身的配置问题，还是集群的DNS出了问题。一个行之有效的方法，就是检查k8s自己的master节点的Service DNS是否正常:
# 在一个 Pod 里执行
$ nslookup kubernetes.default
Server:    10.0.0.10
Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      kubernetes.default
Address 1: 10.0.0.1 kubernetes.default.svc.cluster.local

如果上面访问k8s.default返回的值都有问题，那就需要检查kube-dns的运行状态和日志，否则的话，你应该去检查自己的service定义是不是有问题

而如果你的service没办法通过ClusterIP访问到的时候，你首先应该检查的是这个service是否有endpoints：
kubectl get endpoints hostnames
NAME        ENDPOINTS
hostnames   10.244.0.5:9376,10.244.0.6:9376,10.244.0.7:9376

需要注意的是，如果你的pod的readniessPorbe没通过，它也不会出现在endpoints列表里。


而如果endpoints正常，那么你就需要确认kube-proxy是否在正确运行

如果kube-proxy一切正常，你就应该仔细查看宿主机上的iptables了。而一个iptables模式的Service对应的规则，前面提到过;
包含:
1.KUBE—SERVICES或者KUBE-NODEPOTRS规则对应的Service的入口链，这个规则应该与VIP和Service端口--对应
2.KUBE-SEP-(hash)规则对应的DNAT链，这些规则应该与Endpounts一一对应
3.KUBE-SVC-（hash）规则对应的负载均衡链，这些规则的数目应该与Endpoints数目一致
4.如果是NodePort模式的话，还有POSTROUTING处的SNAT链

通过查看这些链的数量、转发目的地址、端口、过滤条件等信息，你就很容易发现一些异常的蛛丝马迹


当然，还有一种典型的问题，就是Pod没办法通过service访问到自己。这往往就是因为kubelet的hairpin-mode没有被正确设置。
确保将kubelet的hairpin-mode设置为hairpin-veth或者promiscuous-bridge即可

其中，在hairpin-veth模式下，你应该能看到CNI网桥对应的各个VETH设备，都将Hairpin模式设置为了1：
for d in /sys/devices/virtual/net/cni0/brif/veth*/hairpin_mode; do echo "$d = $(cat $d)"; done
/sys/devices/virtual/net/cni0/brif/veth4bfbfe74/hairpin_mode = 1
/sys/devices/virtual/net/cni0/brif/vethfc2a18c5/hairpin_mode = 1

而如果是promiscuous-bridge模式的话，你应该看到CNI网桥的混杂模式（PROMISC）被开启，如下；
ifconfig cni0 |grep PROMISC
UP BROADCAST RUNNING PROMISC MULTICAST  MTU:1460  Metric:1







 






